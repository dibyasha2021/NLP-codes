{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "cAG51Bu1Firs"
      },
      "outputs": [],
      "source": [
        "# basic Libraries\n",
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m9bOWSB7773K",
        "outputId": "e71a1a60-b6c5-424a-9b2e-a3d66b99d356"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "EeqFb8vYZOrr"
      },
      "outputs": [],
      "source": [
        "# the text's are taken from the book \n",
        "# GEORGE ROMNEY BY ROWLEY CLEEVE\n",
        "\n",
        "# text 1 is from chapter 2 LADY HAMILTON\n",
        "text1 = \"In any consideration of the life and art of George Romney, however brief, it is impossible to leave out the name of Lady Hamilton, as she was so constantly painted by him. It will be well, therefore, for a short section of this little book to be devoted to a story of the life of this fascinating person, who was fated to exercise so strong an influence upon the painter. It is hardly possible for the most imaginative romancer to tell a story more chequered in its events, more thrilling in its emotions, and more sad in its end. Emma Lyon was the daughter of a smith in Cheshire, a humble man, who died in 1761, after a very short married life, and left his widow and infant daughter wholly without support. The widow moved at once from Neston, where her husband had died, to Hawarden, her native place, and here by the aid of her relatives, almost equally poor with herself, she managed to bring up her child and send her to a dame's school in the village. When about twelve Emma went as nursery-maid to the family of a Mr. Thomas, a doctor of Hawarden, whose son afterwards became an eminent surgeon.\"\n",
        "# text 2 is from chapter3 THE ART OF ROMNEY\n",
        "text2 = \"Romney is almost exclusively known as a painter of portraits, his historical scenes attracting but little attention. In their way they were remarkable, but they were forced in their conception and over-sentimental in their design, as was the fashion of the day. In his portraits he struck a much truer note and by them his repute will stand. It is almost impossible, taking into consideration the time in which he lived, to avoid comparing him with his great rivals Reynolds and Gainsborough, and perhaps it is well that it should be so, as by thinking of him in connection with these two men it will be possible to obtain a better impression of his capabilities and a knowledge of his faults. He was, it is quite certain, a far less important man than Gainsborough, who must certainly be reckoned as the greatest of the three. He lacked the colour sense that distinguished that great artist; he was by no means his equal in technical merit; and he had no ability to produce landscape-work that gave so great a charm to the pictures of the Sudbury artist. The wonderful poetry that streamed from the brush of Gainsborough and refined all his works, the delicacy, the grace and the sweetness of his figures are all superior qualities to those which Romney possessed, whilst as a colourist Gainsborough stood head and shoulders above both his rivals. When we come to draughtsmanship we are, however, on a different footing, as Romney was the superior both of Reynolds and Gainsborough in ability to draw with accuracy and truth, and he also surpassed both of them in the manner in which he obtained his effects. Where Reynolds laboured Romney achieved the same effect with the greatest ease and simplicity; and, in fact, the word simplicity may be taken as the key-word in anything like a critical survey of Romney's work.\"\n",
        "#text 3 is from chapter 4 OUR ILLUSTRATIONS\n",
        "text3 = \"From the National Gallery we have selected two: a portrait of Mrs. Mark Currie and the portrait called The Parson's Daughter. Mrs. Mark Currie represents a life-size, nearly full-length figure. The lady is dressed in a simple white muslin dress with short sleeves, and an elaborate fichu of the same material. Round her waist is a silk sash of pale red, and the ribbons which trim her sleeves and fichu are of the same pale tint. Her fair hair, slightly powdered, falls in full clusters around her shapely shoulders. Her face wears a quiet thoughtful expression, with a lurking look of humour about the eyes. The background is slightly suggested landscape and trees. The lady was a Miss Elizabeth Close, who married Mr. Mark Currie, a goldsmith and banker, in January, 1789, and gave her first sitting for the portrait on the 7th of May of the same year.It is not known whom The Parson's Daughter represents, nor why it bears that name.It is a very charming circular portrait of a young lady with dark eyes and auburn hair, which is powdered and bound with a green ribbon. She wears a brown dress and white handkerchief. The modelling on the face is very dexterously painted, and the tender thoughtful expression of the dark eyes quite beautiful. The hair is painted in very broad, powerful fashion, and the draperies over the bust indicated lightly and put on with a wonderful sliding movement which is notable. On the whole Romney seldom did a more pleasing piece of work than the portrait of this quiet and refined dainty girl. The Clavering Children, which we have the special permission of the owner (Rev. J. W. Napier-Clavering) to reproduce, is a very happy example of Romney's ability to depict children in movement and to give the effect of rapid motion.\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "1IJZhVjybYSl"
      },
      "outputs": [],
      "source": [
        "# text pre-processing\n",
        "import re\n",
        "import math\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from gensim.parsing.preprocessing import remove_stopwords\n",
        "import nltk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2dSwBkaCcbzr",
        "outputId": "687f456c-6229-4db6-e6e5-8e21fbed3c29"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading collection 'all'\n",
            "[nltk_data]    | \n",
            "[nltk_data]    | Downloading package abc to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/abc.zip.\n",
            "[nltk_data]    | Downloading package alpino to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/alpino.zip.\n",
            "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data]    | Downloading package averaged_perceptron_tagger_ru to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping\n",
            "[nltk_data]    |       taggers/averaged_perceptron_tagger_ru.zip.\n",
            "[nltk_data]    | Downloading package basque_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/basque_grammars.zip.\n",
            "[nltk_data]    | Downloading package biocreative_ppi to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/biocreative_ppi.zip.\n",
            "[nltk_data]    | Downloading package bllip_wsj_no_aux to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping models/bllip_wsj_no_aux.zip.\n",
            "[nltk_data]    | Downloading package book_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/book_grammars.zip.\n",
            "[nltk_data]    | Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/brown.zip.\n",
            "[nltk_data]    | Downloading package brown_tei to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/brown_tei.zip.\n",
            "[nltk_data]    | Downloading package cess_cat to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/cess_cat.zip.\n",
            "[nltk_data]    | Downloading package cess_esp to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/cess_esp.zip.\n",
            "[nltk_data]    | Downloading package chat80 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/chat80.zip.\n",
            "[nltk_data]    | Downloading package city_database to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/city_database.zip.\n",
            "[nltk_data]    | Downloading package cmudict to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/cmudict.zip.\n",
            "[nltk_data]    | Downloading package comparative_sentences to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/comparative_sentences.zip.\n",
            "[nltk_data]    | Downloading package comtrans to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package conll2000 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/conll2000.zip.\n",
            "[nltk_data]    | Downloading package conll2002 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/conll2002.zip.\n",
            "[nltk_data]    | Downloading package conll2007 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package crubadan to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/crubadan.zip.\n",
            "[nltk_data]    | Downloading package dependency_treebank to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/dependency_treebank.zip.\n",
            "[nltk_data]    | Downloading package dolch to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/dolch.zip.\n",
            "[nltk_data]    | Downloading package europarl_raw to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/europarl_raw.zip.\n",
            "[nltk_data]    | Downloading package extended_omw to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package floresta to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/floresta.zip.\n",
            "[nltk_data]    | Downloading package framenet_v15 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/framenet_v15.zip.\n",
            "[nltk_data]    | Downloading package framenet_v17 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/framenet_v17.zip.\n",
            "[nltk_data]    | Downloading package gazetteers to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/gazetteers.zip.\n",
            "[nltk_data]    | Downloading package genesis to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/genesis.zip.\n",
            "[nltk_data]    | Downloading package gutenberg to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/gutenberg.zip.\n",
            "[nltk_data]    | Downloading package ieer to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/ieer.zip.\n",
            "[nltk_data]    | Downloading package inaugural to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/inaugural.zip.\n",
            "[nltk_data]    | Downloading package indian to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/indian.zip.\n",
            "[nltk_data]    | Downloading package jeita to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package kimmo to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/kimmo.zip.\n",
            "[nltk_data]    | Downloading package knbc to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package large_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/large_grammars.zip.\n",
            "[nltk_data]    | Downloading package lin_thesaurus to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/lin_thesaurus.zip.\n",
            "[nltk_data]    | Downloading package mac_morpho to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/mac_morpho.zip.\n",
            "[nltk_data]    | Downloading package machado to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package masc_tagged to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping chunkers/maxent_ne_chunker.zip.\n",
            "[nltk_data]    | Downloading package maxent_treebank_pos_tagger to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping taggers/maxent_treebank_pos_tagger.zip.\n",
            "[nltk_data]    | Downloading package moses_sample to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping models/moses_sample.zip.\n",
            "[nltk_data]    | Downloading package movie_reviews to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/movie_reviews.zip.\n",
            "[nltk_data]    | Downloading package mte_teip5 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/mte_teip5.zip.\n",
            "[nltk_data]    | Downloading package mwa_ppdb to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping misc/mwa_ppdb.zip.\n",
            "[nltk_data]    | Downloading package names to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/names.zip.\n",
            "[nltk_data]    | Downloading package nombank.1.0 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package nonbreaking_prefixes to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/nonbreaking_prefixes.zip.\n",
            "[nltk_data]    | Downloading package nps_chat to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/nps_chat.zip.\n",
            "[nltk_data]    | Downloading package omw to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package opinion_lexicon to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/opinion_lexicon.zip.\n",
            "[nltk_data]    | Downloading package panlex_swadesh to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package paradigms to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/paradigms.zip.\n",
            "[nltk_data]    | Downloading package pe08 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/pe08.zip.\n",
            "[nltk_data]    | Downloading package perluniprops to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping misc/perluniprops.zip.\n",
            "[nltk_data]    | Downloading package pil to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/pil.zip.\n",
            "[nltk_data]    | Downloading package pl196x to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/pl196x.zip.\n",
            "[nltk_data]    | Downloading package porter_test to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping stemmers/porter_test.zip.\n",
            "[nltk_data]    | Downloading package ppattach to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/ppattach.zip.\n",
            "[nltk_data]    | Downloading package problem_reports to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/problem_reports.zip.\n",
            "[nltk_data]    | Downloading package product_reviews_1 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/product_reviews_1.zip.\n",
            "[nltk_data]    | Downloading package product_reviews_2 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/product_reviews_2.zip.\n",
            "[nltk_data]    | Downloading package propbank to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package pros_cons to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/pros_cons.zip.\n",
            "[nltk_data]    | Downloading package ptb to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/ptb.zip.\n",
            "[nltk_data]    | Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data]    | Downloading package qc to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/qc.zip.\n",
            "[nltk_data]    | Downloading package reuters to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package rslp to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping stemmers/rslp.zip.\n",
            "[nltk_data]    | Downloading package rte to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/rte.zip.\n",
            "[nltk_data]    | Downloading package sample_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/sample_grammars.zip.\n",
            "[nltk_data]    | Downloading package semcor to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package senseval to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/senseval.zip.\n",
            "[nltk_data]    | Downloading package sentence_polarity to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/sentence_polarity.zip.\n",
            "[nltk_data]    | Downloading package sentiwordnet to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/sentiwordnet.zip.\n",
            "[nltk_data]    | Downloading package shakespeare to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/shakespeare.zip.\n",
            "[nltk_data]    | Downloading package sinica_treebank to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/sinica_treebank.zip.\n",
            "[nltk_data]    | Downloading package smultron to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/smultron.zip.\n",
            "[nltk_data]    | Downloading package snowball_data to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package spanish_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/spanish_grammars.zip.\n",
            "[nltk_data]    | Downloading package state_union to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/state_union.zip.\n",
            "[nltk_data]    | Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data]    | Downloading package subjectivity to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/subjectivity.zip.\n",
            "[nltk_data]    | Downloading package swadesh to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/swadesh.zip.\n",
            "[nltk_data]    | Downloading package switchboard to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/switchboard.zip.\n",
            "[nltk_data]    | Downloading package tagsets to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping help/tagsets.zip.\n",
            "[nltk_data]    | Downloading package timit to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/timit.zip.\n",
            "[nltk_data]    | Downloading package toolbox to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/toolbox.zip.\n",
            "[nltk_data]    | Downloading package treebank to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/treebank.zip.\n",
            "[nltk_data]    | Downloading package twitter_samples to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/twitter_samples.zip.\n",
            "[nltk_data]    | Downloading package udhr to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/udhr.zip.\n",
            "[nltk_data]    | Downloading package udhr2 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/udhr2.zip.\n",
            "[nltk_data]    | Downloading package unicode_samples to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/unicode_samples.zip.\n",
            "[nltk_data]    | Downloading package universal_tagset to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping taggers/universal_tagset.zip.\n",
            "[nltk_data]    | Downloading package universal_treebanks_v20 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package vader_lexicon to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package verbnet to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/verbnet.zip.\n",
            "[nltk_data]    | Downloading package verbnet3 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/verbnet3.zip.\n",
            "[nltk_data]    | Downloading package webtext to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/webtext.zip.\n",
            "[nltk_data]    | Downloading package wmt15_eval to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping models/wmt15_eval.zip.\n",
            "[nltk_data]    | Downloading package word2vec_sample to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping models/word2vec_sample.zip.\n",
            "[nltk_data]    | Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package wordnet2021 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package wordnet31 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package wordnet_ic to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/wordnet_ic.zip.\n",
            "[nltk_data]    | Downloading package words to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/words.zip.\n",
            "[nltk_data]    | Downloading package ycoe to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/ycoe.zip.\n",
            "[nltk_data]    | \n",
            "[nltk_data]  Done downloading collection all\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "nltk.download('all')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "qfkz9ZDrcfXV"
      },
      "outputs": [],
      "source": [
        "# List of the documents\n",
        "Doc_list=[text1,text2,text3]\n",
        "# making dataframe from the document list\n",
        "Dataset=pd.DataFrame(Doc_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "A5RDlkD8dDiH"
      },
      "outputs": [],
      "source": [
        "Dataset = Dataset.rename(columns = {0:'Documents'})\n",
        "#Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "VrFc0Pqkd093"
      },
      "outputs": [],
      "source": [
        "# Merging all the doc into one\n",
        "# accessing the document no.\n",
        "All_Docs=[]\n",
        "for y in range(3): \n",
        "  docs=Dataset.iloc[y][\"Documents\"]\n",
        "  All_Docs.append(docs)\n",
        "#All_Docs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "-krO50pLf2I5"
      },
      "outputs": [],
      "source": [
        "## importing library for punctuatuin removal\n",
        "import string\n",
        "#string.punctuation\n",
        "# Initializing the tokenniers\n",
        "w_tokenizer = nltk.tokenize.WhitespaceTokenizer()\n",
        "lemmatizer = nltk.stem.WordNetLemmatizer()\n",
        "\n",
        "# for stopwords\n",
        "remove_stop= nltk.corpus.stopwords.words('english')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "id": "4SrmNvs9kFVo",
        "outputId": "2b7b951a-bd56-4f0d-f237-bd198a092d49"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                           Documents  \\\n",
              "0  In any consideration of the life and art of Ge...   \n",
              "1  Romney is almost exclusively known as a painte...   \n",
              "2  From the National Gallery we have selected two...   \n",
              "\n",
              "                                            No_punct  \\\n",
              "0  in any consideration of the life and art of ge...   \n",
              "1  romney is almost exclusively known as a painte...   \n",
              "2  from the national gallery we have selected two...   \n",
              "\n",
              "                                               final  \\\n",
              "0  [in, any, consideration, of, the, life, and, a...   \n",
              "1  [romney, is, almost, exclusively, known, a, a,...   \n",
              "2  [from, the, national, gallery, we, have, selec...   \n",
              "\n",
              "                                   Pre+processed_doc  \n",
              "0  [consideration, life, art, george, romney, bri...  \n",
              "1  [romney, exclusively, known, painter, portrait...  \n",
              "2  [national, gallery, selected, portrait, mr, ma...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1a8d2495-b0db-4365-94ce-a71b40eb8e89\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Documents</th>\n",
              "      <th>No_punct</th>\n",
              "      <th>final</th>\n",
              "      <th>Pre+processed_doc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>In any consideration of the life and art of Ge...</td>\n",
              "      <td>in any consideration of the life and art of ge...</td>\n",
              "      <td>[in, any, consideration, of, the, life, and, a...</td>\n",
              "      <td>[consideration, life, art, george, romney, bri...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Romney is almost exclusively known as a painte...</td>\n",
              "      <td>romney is almost exclusively known as a painte...</td>\n",
              "      <td>[romney, is, almost, exclusively, known, a, a,...</td>\n",
              "      <td>[romney, exclusively, known, painter, portrait...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>From the National Gallery we have selected two...</td>\n",
              "      <td>from the national gallery we have selected two...</td>\n",
              "      <td>[from, the, national, gallery, we, have, selec...</td>\n",
              "      <td>[national, gallery, selected, portrait, mr, ma...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1a8d2495-b0db-4365-94ce-a71b40eb8e89')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-1a8d2495-b0db-4365-94ce-a71b40eb8e89 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-1a8d2495-b0db-4365-94ce-a71b40eb8e89');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "# function to remove puncuation and lowercasing the text\n",
        "\n",
        "def remove_punctuation(text):\n",
        "      \n",
        "    for i in range(len(text)):\n",
        "      punctuationfree=\"\".join([i for i in text if i not in string.punctuation])\n",
        "      punct_free=punctuationfree.lower()    \n",
        "    return punct_free\n",
        "\n",
        "Dataset['No_punct']= Dataset['Documents'].apply(lambda x:remove_punctuation(x))\n",
        "\n",
        "def lemmatize_text(punct_free):\n",
        "  text =punct_free\n",
        "  token_data=[lemmatizer.lemmatize(w) for w in w_tokenizer.tokenize(text)]\n",
        "  return token_data\n",
        "\n",
        "Dataset['final']= Dataset['No_punct'].apply(lambda x:lemmatize_text(x))\n",
        "\n",
        "def stopwords_removal(token_data):\n",
        "  text =token_data\n",
        "  output=[]\n",
        "  for i in text:\n",
        "    ft=remove_stopwords(i)\n",
        "    if ft == '':\n",
        "      continue \n",
        "    else :\n",
        "      output.append(ft)\n",
        "  return output\n",
        "  \n",
        "\n",
        "\n",
        "#applying the function to the document\n",
        "Dataset['Pre+processed_doc']= Dataset['final'].apply(lambda x:stopwords_removal(x))\n",
        "Dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "zDXrW5dxpuRm",
        "outputId": "cc9184e9-dca2-43a9-c3ff-05b5912cc502"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                           Documents  \\\n",
              "0  In any consideration of the life and art of Ge...   \n",
              "1  Romney is almost exclusively known as a painte...   \n",
              "2  From the National Gallery we have selected two...   \n",
              "\n",
              "                                   Pre+processed_doc  \n",
              "0  [consideration, life, art, george, romney, bri...  \n",
              "1  [romney, exclusively, known, painter, portrait...  \n",
              "2  [national, gallery, selected, portrait, mr, ma...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-939f3051-2519-4e09-800f-18b2326907b4\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Documents</th>\n",
              "      <th>Pre+processed_doc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>In any consideration of the life and art of Ge...</td>\n",
              "      <td>[consideration, life, art, george, romney, bri...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Romney is almost exclusively known as a painte...</td>\n",
              "      <td>[romney, exclusively, known, painter, portrait...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>From the National Gallery we have selected two...</td>\n",
              "      <td>[national, gallery, selected, portrait, mr, ma...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-939f3051-2519-4e09-800f-18b2326907b4')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-939f3051-2519-4e09-800f-18b2326907b4 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-939f3051-2519-4e09-800f-18b2326907b4');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "Dataset=Dataset.drop(columns=['No_punct','final'],axis=1)\n",
        "Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3YJkX3zetQyQ",
        "outputId": "72aed072-02bd-4b3d-e585-dc15ffb8cf35"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['consideration', 'life', 'art', 'george', 'romney', 'brief', 'impossible', 'leave', 'lady', 'hamilton', 'wa', 'constantly', 'painted', 'short', 'section', 'little', 'book', 'devoted', 'story', 'life', 'fascinating', 'person', 'wa', 'fated', 'exercise', 'strong', 'influence', 'painter', 'hardly', 'possible', 'imaginative', 'romancer', 'tell', 'story', 'chequered', 'event', 'thrilling', 'emotion', 'sad', 'end', 'emma', 'lyon', 'wa', 'daughter', 'smith', 'cheshire', 'humble', 'man', 'died', '1761', 'short', 'married', 'life', 'left', 'widow', 'infant', 'daughter', 'wholly', 'support', 'widow', 'moved', 'neston', 'husband', 'died', 'hawarden', 'native', 'place', 'aid', 'relative', 'equally', 'poor', 'managed', 'bring', 'child', 'send', 'dame', 'school', 'village', 'emma', 'went', 'nurserymaid', 'family', 'mr', 'thomas', 'doctor', 'hawarden', 'son', 'eminent', 'surgeon'], ['romney', 'exclusively', 'known', 'painter', 'portrait', 'historical', 'scene', 'attracting', 'little', 'attention', 'way', 'remarkable', 'forced', 'conception', 'oversentimental', 'design', 'wa', 'fashion', 'day', 'portrait', 'struck', 'truer', 'note', 'repute', 'stand', 'impossible', 'taking', 'consideration', 'time', 'lived', 'avoid', 'comparing', 'great', 'rival', 'reynolds', 'gainsborough', 'thinking', 'connection', 'men', 'possible', 'obtain', 'better', 'impression', 'capability', 'knowledge', 'fault', 'wa', 'certain', 'far', 'le', 'important', 'man', 'gainsborough', 'certainly', 'reckoned', 'greatest', 'lacked', 'colour', 'sense', 'distinguished', 'great', 'artist', 'wa', 'mean', 'equal', 'technical', 'merit', 'ability', 'produce', 'landscapework', 'gave', 'great', 'charm', 'picture', 'sudbury', 'artist', 'wonderful', 'poetry', 'streamed', 'brush', 'gainsborough', 'refined', 'work', 'delicacy', 'grace', 'sweetness', 'figure', 'superior', 'quality', 'romney', 'possessed', 'whilst', 'colourist', 'gainsborough', 'stood', 'head', 'shoulder', 'rival', 'come', 'draughtsmanship', 'different', 'footing', 'romney', 'wa', 'superior', 'reynolds', 'gainsborough', 'ability', 'draw', 'accuracy', 'truth', 'surpassed', 'manner', 'obtained', 'effect', 'reynolds', 'laboured', 'romney', 'achieved', 'effect', 'greatest', 'ease', 'simplicity', 'fact', 'word', 'simplicity', 'taken', 'keyword', 'like', 'critical', 'survey', 'romneys', 'work'], ['national', 'gallery', 'selected', 'portrait', 'mr', 'mark', 'currie', 'portrait', 'called', 'parson', 'daughter', 'mr', 'mark', 'currie', 'represents', 'lifesize', 'nearly', 'fulllength', 'figure', 'lady', 'dressed', 'simple', 'white', 'muslin', 'dress', 'short', 'sleeve', 'elaborate', 'fichu', 'material', 'round', 'waist', 'silk', 'sash', 'pale', 'red', 'ribbon', 'trim', 'sleeve', 'fichu', 'pale', 'tint', 'fair', 'hair', 'slightly', 'powdered', 'fall', 'cluster', 'shapely', 'shoulder', 'face', 'wear', 'quiet', 'thoughtful', 'expression', 'lurking', 'look', 'humour', 'eye', 'background', 'slightly', 'suggested', 'landscape', 'tree', 'lady', 'wa', 'miss', 'elizabeth', 'close', 'married', 'mr', 'mark', 'currie', 'goldsmith', 'banker', 'january', '1789', 'gave', 'sitting', 'portrait', '7th', 'yearit', 'known', 'parson', 'daughter', 'represents', 'bear', 'nameit', 'charming', 'circular', 'portrait', 'young', 'lady', 'dark', 'eye', 'auburn', 'hair', 'powdered', 'bound', 'green', 'ribbon', 'wear', 'brown', 'dress', 'white', 'handkerchief', 'modelling', 'face', 'dexterously', 'painted', 'tender', 'thoughtful', 'expression', 'dark', 'eye', 'beautiful', 'hair', 'painted', 'broad', 'powerful', 'fashion', 'drapery', 'bust', 'indicated', 'lightly', 'wonderful', 'sliding', 'movement', 'notable', 'romney', 'seldom', 'pleasing', 'piece', 'work', 'portrait', 'quiet', 'refined', 'dainty', 'girl', 'clavering', 'child', 'special', 'permission', 'owner', 'rev', 'j', 'w', 'napierclavering', 'reproduce', 'happy', 'example', 'romneys', 'ability', 'depict', 'child', 'movement', 'effect', 'rapid', 'motion']]\n"
          ]
        }
      ],
      "source": [
        "#ALL the documents\n",
        "#All_Docs\n",
        "\n",
        "# list of words in douments\n",
        "All_words=[]\n",
        "for y in range(3):\n",
        "  documents=Dataset.iloc[y][\"Pre+processed_doc\"]\n",
        "  All_words.append(documents)\n",
        "print(All_words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "dlfxl5FVxsYx"
      },
      "outputs": [],
      "source": [
        "#finding Unique words in all  the documents\n",
        "def Unique_words(list_of_tokens):\n",
        "  n=len(list_of_tokens)\n",
        "  s=1\n",
        "  wordset=set(list_of_tokens[0])\n",
        "  while s<n:\n",
        "    Uniq_wordset=wordset.union(set(list_of_tokens[s]))\n",
        "    s=s+1\n",
        "  return Uniq_wordset\n",
        "\n",
        "\n",
        "# set of unique words\n",
        "Uniq_words=Unique_words(All_words)\n",
        "#Uniq_words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ey84WAX56WeA",
        "outputId": "dedbf657-7495-40fd-f015-c08cd6f40b98"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "int(bool(2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "5cpQJOW1zhl6"
      },
      "outputs": [],
      "source": [
        "# Calculating Bag of words\n",
        "def calculateBOW(wordset,doc):\n",
        "  tf_diz = dict.fromkeys(wordset,0)\n",
        "  for word in doc:\n",
        "      tf_diz[word]=int(bool(doc.count(word)))\n",
        "\n",
        "  return tf_diz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AOFw6dkyz07u",
        "outputId": "97c780ff-7744-42d7-8dd3-7cbae97bdf66"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'seldom': 0,\n",
              "  'surgeon': 1,\n",
              "  'story': 1,\n",
              "  'leave': 1,\n",
              "  'motion': 0,\n",
              "  'thrilling': 1,\n",
              "  'bound': 0,\n",
              "  'eye': 0,\n",
              "  'managed': 1,\n",
              "  'nearly': 0,\n",
              "  'owner': 0,\n",
              "  'refined': 0,\n",
              "  'drapery': 0,\n",
              "  'january': 0,\n",
              "  'simple': 0,\n",
              "  'elizabeth': 0,\n",
              "  'brief': 1,\n",
              "  'humble': 1,\n",
              "  'hamilton': 1,\n",
              "  'equally': 1,\n",
              "  'neston': 1,\n",
              "  'elaborate': 0,\n",
              "  'rapid': 0,\n",
              "  'thomas': 1,\n",
              "  'section': 1,\n",
              "  'fichu': 0,\n",
              "  'material': 0,\n",
              "  'mr': 1,\n",
              "  'tint': 0,\n",
              "  'school': 1,\n",
              "  'infant': 1,\n",
              "  'happy': 0,\n",
              "  'slightly': 0,\n",
              "  'shapely': 0,\n",
              "  'depict': 0,\n",
              "  'tree': 0,\n",
              "  'brown': 0,\n",
              "  'painted': 1,\n",
              "  'hawarden': 1,\n",
              "  'look': 0,\n",
              "  'banker': 0,\n",
              "  '7th': 0,\n",
              "  'close': 0,\n",
              "  'bring': 1,\n",
              "  'cheshire': 1,\n",
              "  'widow': 1,\n",
              "  'currie': 0,\n",
              "  'person': 1,\n",
              "  'fall': 0,\n",
              "  'man': 1,\n",
              "  'portrait': 0,\n",
              "  'reproduce': 0,\n",
              "  'exercise': 1,\n",
              "  'modelling': 0,\n",
              "  'eminent': 1,\n",
              "  'expression': 0,\n",
              "  'aid': 1,\n",
              "  'romancer': 1,\n",
              "  'powdered': 0,\n",
              "  'rev': 0,\n",
              "  'handkerchief': 0,\n",
              "  'background': 0,\n",
              "  'consideration': 1,\n",
              "  'called': 0,\n",
              "  'child': 1,\n",
              "  'emotion': 1,\n",
              "  'doctor': 1,\n",
              "  'impossible': 1,\n",
              "  'selected': 0,\n",
              "  'painter': 1,\n",
              "  'bust': 0,\n",
              "  'lyon': 1,\n",
              "  'lurking': 0,\n",
              "  'muslin': 0,\n",
              "  'sliding': 0,\n",
              "  'chequered': 1,\n",
              "  'mark': 0,\n",
              "  'known': 0,\n",
              "  'lifesize': 0,\n",
              "  'beautiful': 0,\n",
              "  'influence': 1,\n",
              "  'ability': 0,\n",
              "  'sash': 0,\n",
              "  'relative': 1,\n",
              "  'permission': 0,\n",
              "  'sad': 1,\n",
              "  'clavering': 0,\n",
              "  'circular': 0,\n",
              "  'broad': 0,\n",
              "  'example': 0,\n",
              "  'tender': 0,\n",
              "  'effect': 0,\n",
              "  'j': 0,\n",
              "  'green': 0,\n",
              "  'event': 1,\n",
              "  'village': 1,\n",
              "  'romneys': 0,\n",
              "  'figure': 0,\n",
              "  'quiet': 0,\n",
              "  'ribbon': 0,\n",
              "  'gave': 0,\n",
              "  'bear': 0,\n",
              "  'fashion': 0,\n",
              "  'dressed': 0,\n",
              "  'goldsmith': 0,\n",
              "  'face': 0,\n",
              "  'wonderful': 0,\n",
              "  'fascinating': 1,\n",
              "  'nurserymaid': 1,\n",
              "  'auburn': 0,\n",
              "  'constantly': 1,\n",
              "  'cluster': 0,\n",
              "  'charming': 0,\n",
              "  'possible': 1,\n",
              "  'married': 1,\n",
              "  'little': 1,\n",
              "  'support': 1,\n",
              "  'miss': 0,\n",
              "  'national': 0,\n",
              "  'piece': 0,\n",
              "  'art': 1,\n",
              "  'devoted': 1,\n",
              "  'strong': 1,\n",
              "  'book': 1,\n",
              "  'suggested': 0,\n",
              "  'gallery': 0,\n",
              "  'red': 0,\n",
              "  'sitting': 0,\n",
              "  'imaginative': 1,\n",
              "  'pale': 0,\n",
              "  'napierclavering': 0,\n",
              "  'family': 1,\n",
              "  'place': 1,\n",
              "  'native': 1,\n",
              "  'pleasing': 0,\n",
              "  'son': 1,\n",
              "  'movement': 0,\n",
              "  'send': 1,\n",
              "  'represents': 0,\n",
              "  'dress': 0,\n",
              "  'husband': 1,\n",
              "  'hair': 0,\n",
              "  'notable': 0,\n",
              "  'waist': 0,\n",
              "  'wholly': 1,\n",
              "  'girl': 0,\n",
              "  'trim': 0,\n",
              "  'went': 1,\n",
              "  'parson': 0,\n",
              "  'silk': 0,\n",
              "  'w': 0,\n",
              "  'white': 0,\n",
              "  'young': 0,\n",
              "  'end': 1,\n",
              "  'shoulder': 0,\n",
              "  'hardly': 1,\n",
              "  'yearit': 0,\n",
              "  'emma': 1,\n",
              "  'special': 0,\n",
              "  'fulllength': 0,\n",
              "  'romney': 1,\n",
              "  'indicated': 0,\n",
              "  'wear': 0,\n",
              "  '1761': 1,\n",
              "  'lightly': 0,\n",
              "  'left': 1,\n",
              "  'dark': 0,\n",
              "  'round': 0,\n",
              "  'lady': 1,\n",
              "  'sleeve': 0,\n",
              "  'landscape': 0,\n",
              "  'thoughtful': 0,\n",
              "  'tell': 1,\n",
              "  '1789': 0,\n",
              "  'died': 1,\n",
              "  'fair': 0,\n",
              "  'powerful': 0,\n",
              "  'poor': 1,\n",
              "  'george': 1,\n",
              "  'fated': 1,\n",
              "  'short': 1,\n",
              "  'wa': 1,\n",
              "  'dame': 1,\n",
              "  'smith': 1,\n",
              "  'humour': 0,\n",
              "  'dainty': 0,\n",
              "  'work': 0,\n",
              "  'moved': 1,\n",
              "  'nameit': 0,\n",
              "  'dexterously': 0,\n",
              "  'life': 1,\n",
              "  'daughter': 1},\n",
              " {'seldom': 0,\n",
              "  'surgeon': 0,\n",
              "  'story': 0,\n",
              "  'leave': 0,\n",
              "  'motion': 0,\n",
              "  'thrilling': 0,\n",
              "  'bound': 0,\n",
              "  'eye': 0,\n",
              "  'managed': 0,\n",
              "  'nearly': 0,\n",
              "  'owner': 0,\n",
              "  'refined': 1,\n",
              "  'drapery': 0,\n",
              "  'january': 0,\n",
              "  'simple': 0,\n",
              "  'elizabeth': 0,\n",
              "  'brief': 0,\n",
              "  'humble': 0,\n",
              "  'hamilton': 0,\n",
              "  'equally': 0,\n",
              "  'neston': 0,\n",
              "  'elaborate': 0,\n",
              "  'rapid': 0,\n",
              "  'thomas': 0,\n",
              "  'section': 0,\n",
              "  'fichu': 0,\n",
              "  'material': 0,\n",
              "  'mr': 0,\n",
              "  'tint': 0,\n",
              "  'school': 0,\n",
              "  'infant': 0,\n",
              "  'happy': 0,\n",
              "  'slightly': 0,\n",
              "  'shapely': 0,\n",
              "  'depict': 0,\n",
              "  'tree': 0,\n",
              "  'brown': 0,\n",
              "  'painted': 0,\n",
              "  'hawarden': 0,\n",
              "  'look': 0,\n",
              "  'banker': 0,\n",
              "  '7th': 0,\n",
              "  'close': 0,\n",
              "  'bring': 0,\n",
              "  'cheshire': 0,\n",
              "  'widow': 0,\n",
              "  'currie': 0,\n",
              "  'person': 0,\n",
              "  'fall': 0,\n",
              "  'man': 1,\n",
              "  'portrait': 1,\n",
              "  'reproduce': 0,\n",
              "  'exercise': 0,\n",
              "  'modelling': 0,\n",
              "  'eminent': 0,\n",
              "  'expression': 0,\n",
              "  'aid': 0,\n",
              "  'romancer': 0,\n",
              "  'powdered': 0,\n",
              "  'rev': 0,\n",
              "  'handkerchief': 0,\n",
              "  'background': 0,\n",
              "  'consideration': 1,\n",
              "  'called': 0,\n",
              "  'child': 0,\n",
              "  'emotion': 0,\n",
              "  'doctor': 0,\n",
              "  'impossible': 1,\n",
              "  'selected': 0,\n",
              "  'painter': 1,\n",
              "  'bust': 0,\n",
              "  'lyon': 0,\n",
              "  'lurking': 0,\n",
              "  'muslin': 0,\n",
              "  'sliding': 0,\n",
              "  'chequered': 0,\n",
              "  'mark': 0,\n",
              "  'known': 1,\n",
              "  'lifesize': 0,\n",
              "  'beautiful': 0,\n",
              "  'influence': 0,\n",
              "  'ability': 1,\n",
              "  'sash': 0,\n",
              "  'relative': 0,\n",
              "  'permission': 0,\n",
              "  'sad': 0,\n",
              "  'clavering': 0,\n",
              "  'circular': 0,\n",
              "  'broad': 0,\n",
              "  'example': 0,\n",
              "  'tender': 0,\n",
              "  'effect': 1,\n",
              "  'j': 0,\n",
              "  'green': 0,\n",
              "  'event': 0,\n",
              "  'village': 0,\n",
              "  'romneys': 1,\n",
              "  'figure': 1,\n",
              "  'quiet': 0,\n",
              "  'ribbon': 0,\n",
              "  'gave': 1,\n",
              "  'bear': 0,\n",
              "  'fashion': 1,\n",
              "  'dressed': 0,\n",
              "  'goldsmith': 0,\n",
              "  'face': 0,\n",
              "  'wonderful': 1,\n",
              "  'fascinating': 0,\n",
              "  'nurserymaid': 0,\n",
              "  'auburn': 0,\n",
              "  'constantly': 0,\n",
              "  'cluster': 0,\n",
              "  'charming': 0,\n",
              "  'possible': 1,\n",
              "  'married': 0,\n",
              "  'little': 1,\n",
              "  'support': 0,\n",
              "  'miss': 0,\n",
              "  'national': 0,\n",
              "  'piece': 0,\n",
              "  'art': 0,\n",
              "  'devoted': 0,\n",
              "  'strong': 0,\n",
              "  'book': 0,\n",
              "  'suggested': 0,\n",
              "  'gallery': 0,\n",
              "  'red': 0,\n",
              "  'sitting': 0,\n",
              "  'imaginative': 0,\n",
              "  'pale': 0,\n",
              "  'napierclavering': 0,\n",
              "  'family': 0,\n",
              "  'place': 0,\n",
              "  'native': 0,\n",
              "  'pleasing': 0,\n",
              "  'son': 0,\n",
              "  'movement': 0,\n",
              "  'send': 0,\n",
              "  'represents': 0,\n",
              "  'dress': 0,\n",
              "  'husband': 0,\n",
              "  'hair': 0,\n",
              "  'notable': 0,\n",
              "  'waist': 0,\n",
              "  'wholly': 0,\n",
              "  'girl': 0,\n",
              "  'trim': 0,\n",
              "  'went': 0,\n",
              "  'parson': 0,\n",
              "  'silk': 0,\n",
              "  'w': 0,\n",
              "  'white': 0,\n",
              "  'young': 0,\n",
              "  'end': 0,\n",
              "  'shoulder': 1,\n",
              "  'hardly': 0,\n",
              "  'yearit': 0,\n",
              "  'emma': 0,\n",
              "  'special': 0,\n",
              "  'fulllength': 0,\n",
              "  'romney': 1,\n",
              "  'indicated': 0,\n",
              "  'wear': 0,\n",
              "  '1761': 0,\n",
              "  'lightly': 0,\n",
              "  'left': 0,\n",
              "  'dark': 0,\n",
              "  'round': 0,\n",
              "  'lady': 0,\n",
              "  'sleeve': 0,\n",
              "  'landscape': 0,\n",
              "  'thoughtful': 0,\n",
              "  'tell': 0,\n",
              "  '1789': 0,\n",
              "  'died': 0,\n",
              "  'fair': 0,\n",
              "  'powerful': 0,\n",
              "  'poor': 0,\n",
              "  'george': 0,\n",
              "  'fated': 0,\n",
              "  'short': 0,\n",
              "  'wa': 1,\n",
              "  'dame': 0,\n",
              "  'smith': 0,\n",
              "  'humour': 0,\n",
              "  'dainty': 0,\n",
              "  'work': 1,\n",
              "  'moved': 0,\n",
              "  'nameit': 0,\n",
              "  'dexterously': 0,\n",
              "  'life': 0,\n",
              "  'daughter': 0,\n",
              "  'exclusively': 1,\n",
              "  'historical': 1,\n",
              "  'scene': 1,\n",
              "  'attracting': 1,\n",
              "  'attention': 1,\n",
              "  'way': 1,\n",
              "  'remarkable': 1,\n",
              "  'forced': 1,\n",
              "  'conception': 1,\n",
              "  'oversentimental': 1,\n",
              "  'design': 1,\n",
              "  'day': 1,\n",
              "  'struck': 1,\n",
              "  'truer': 1,\n",
              "  'note': 1,\n",
              "  'repute': 1,\n",
              "  'stand': 1,\n",
              "  'taking': 1,\n",
              "  'time': 1,\n",
              "  'lived': 1,\n",
              "  'avoid': 1,\n",
              "  'comparing': 1,\n",
              "  'great': 1,\n",
              "  'rival': 1,\n",
              "  'reynolds': 1,\n",
              "  'gainsborough': 1,\n",
              "  'thinking': 1,\n",
              "  'connection': 1,\n",
              "  'men': 1,\n",
              "  'obtain': 1,\n",
              "  'better': 1,\n",
              "  'impression': 1,\n",
              "  'capability': 1,\n",
              "  'knowledge': 1,\n",
              "  'fault': 1,\n",
              "  'certain': 1,\n",
              "  'far': 1,\n",
              "  'le': 1,\n",
              "  'important': 1,\n",
              "  'certainly': 1,\n",
              "  'reckoned': 1,\n",
              "  'greatest': 1,\n",
              "  'lacked': 1,\n",
              "  'colour': 1,\n",
              "  'sense': 1,\n",
              "  'distinguished': 1,\n",
              "  'artist': 1,\n",
              "  'mean': 1,\n",
              "  'equal': 1,\n",
              "  'technical': 1,\n",
              "  'merit': 1,\n",
              "  'produce': 1,\n",
              "  'landscapework': 1,\n",
              "  'charm': 1,\n",
              "  'picture': 1,\n",
              "  'sudbury': 1,\n",
              "  'poetry': 1,\n",
              "  'streamed': 1,\n",
              "  'brush': 1,\n",
              "  'delicacy': 1,\n",
              "  'grace': 1,\n",
              "  'sweetness': 1,\n",
              "  'superior': 1,\n",
              "  'quality': 1,\n",
              "  'possessed': 1,\n",
              "  'whilst': 1,\n",
              "  'colourist': 1,\n",
              "  'stood': 1,\n",
              "  'head': 1,\n",
              "  'come': 1,\n",
              "  'draughtsmanship': 1,\n",
              "  'different': 1,\n",
              "  'footing': 1,\n",
              "  'draw': 1,\n",
              "  'accuracy': 1,\n",
              "  'truth': 1,\n",
              "  'surpassed': 1,\n",
              "  'manner': 1,\n",
              "  'obtained': 1,\n",
              "  'laboured': 1,\n",
              "  'achieved': 1,\n",
              "  'ease': 1,\n",
              "  'simplicity': 1,\n",
              "  'fact': 1,\n",
              "  'word': 1,\n",
              "  'taken': 1,\n",
              "  'keyword': 1,\n",
              "  'like': 1,\n",
              "  'critical': 1,\n",
              "  'survey': 1},\n",
              " {'seldom': 1,\n",
              "  'surgeon': 0,\n",
              "  'story': 0,\n",
              "  'leave': 0,\n",
              "  'motion': 1,\n",
              "  'thrilling': 0,\n",
              "  'bound': 1,\n",
              "  'eye': 1,\n",
              "  'managed': 0,\n",
              "  'nearly': 1,\n",
              "  'owner': 1,\n",
              "  'refined': 1,\n",
              "  'drapery': 1,\n",
              "  'january': 1,\n",
              "  'simple': 1,\n",
              "  'elizabeth': 1,\n",
              "  'brief': 0,\n",
              "  'humble': 0,\n",
              "  'hamilton': 0,\n",
              "  'equally': 0,\n",
              "  'neston': 0,\n",
              "  'elaborate': 1,\n",
              "  'rapid': 1,\n",
              "  'thomas': 0,\n",
              "  'section': 0,\n",
              "  'fichu': 1,\n",
              "  'material': 1,\n",
              "  'mr': 1,\n",
              "  'tint': 1,\n",
              "  'school': 0,\n",
              "  'infant': 0,\n",
              "  'happy': 1,\n",
              "  'slightly': 1,\n",
              "  'shapely': 1,\n",
              "  'depict': 1,\n",
              "  'tree': 1,\n",
              "  'brown': 1,\n",
              "  'painted': 1,\n",
              "  'hawarden': 0,\n",
              "  'look': 1,\n",
              "  'banker': 1,\n",
              "  '7th': 1,\n",
              "  'close': 1,\n",
              "  'bring': 0,\n",
              "  'cheshire': 0,\n",
              "  'widow': 0,\n",
              "  'currie': 1,\n",
              "  'person': 0,\n",
              "  'fall': 1,\n",
              "  'man': 0,\n",
              "  'portrait': 1,\n",
              "  'reproduce': 1,\n",
              "  'exercise': 0,\n",
              "  'modelling': 1,\n",
              "  'eminent': 0,\n",
              "  'expression': 1,\n",
              "  'aid': 0,\n",
              "  'romancer': 0,\n",
              "  'powdered': 1,\n",
              "  'rev': 1,\n",
              "  'handkerchief': 1,\n",
              "  'background': 1,\n",
              "  'consideration': 0,\n",
              "  'called': 1,\n",
              "  'child': 1,\n",
              "  'emotion': 0,\n",
              "  'doctor': 0,\n",
              "  'impossible': 0,\n",
              "  'selected': 1,\n",
              "  'painter': 0,\n",
              "  'bust': 1,\n",
              "  'lyon': 0,\n",
              "  'lurking': 1,\n",
              "  'muslin': 1,\n",
              "  'sliding': 1,\n",
              "  'chequered': 0,\n",
              "  'mark': 1,\n",
              "  'known': 1,\n",
              "  'lifesize': 1,\n",
              "  'beautiful': 1,\n",
              "  'influence': 0,\n",
              "  'ability': 1,\n",
              "  'sash': 1,\n",
              "  'relative': 0,\n",
              "  'permission': 1,\n",
              "  'sad': 0,\n",
              "  'clavering': 1,\n",
              "  'circular': 1,\n",
              "  'broad': 1,\n",
              "  'example': 1,\n",
              "  'tender': 1,\n",
              "  'effect': 1,\n",
              "  'j': 1,\n",
              "  'green': 1,\n",
              "  'event': 0,\n",
              "  'village': 0,\n",
              "  'romneys': 1,\n",
              "  'figure': 1,\n",
              "  'quiet': 1,\n",
              "  'ribbon': 1,\n",
              "  'gave': 1,\n",
              "  'bear': 1,\n",
              "  'fashion': 1,\n",
              "  'dressed': 1,\n",
              "  'goldsmith': 1,\n",
              "  'face': 1,\n",
              "  'wonderful': 1,\n",
              "  'fascinating': 0,\n",
              "  'nurserymaid': 0,\n",
              "  'auburn': 1,\n",
              "  'constantly': 0,\n",
              "  'cluster': 1,\n",
              "  'charming': 1,\n",
              "  'possible': 0,\n",
              "  'married': 1,\n",
              "  'little': 0,\n",
              "  'support': 0,\n",
              "  'miss': 1,\n",
              "  'national': 1,\n",
              "  'piece': 1,\n",
              "  'art': 0,\n",
              "  'devoted': 0,\n",
              "  'strong': 0,\n",
              "  'book': 0,\n",
              "  'suggested': 1,\n",
              "  'gallery': 1,\n",
              "  'red': 1,\n",
              "  'sitting': 1,\n",
              "  'imaginative': 0,\n",
              "  'pale': 1,\n",
              "  'napierclavering': 1,\n",
              "  'family': 0,\n",
              "  'place': 0,\n",
              "  'native': 0,\n",
              "  'pleasing': 1,\n",
              "  'son': 0,\n",
              "  'movement': 1,\n",
              "  'send': 0,\n",
              "  'represents': 1,\n",
              "  'dress': 1,\n",
              "  'husband': 0,\n",
              "  'hair': 1,\n",
              "  'notable': 1,\n",
              "  'waist': 1,\n",
              "  'wholly': 0,\n",
              "  'girl': 1,\n",
              "  'trim': 1,\n",
              "  'went': 0,\n",
              "  'parson': 1,\n",
              "  'silk': 1,\n",
              "  'w': 1,\n",
              "  'white': 1,\n",
              "  'young': 1,\n",
              "  'end': 0,\n",
              "  'shoulder': 1,\n",
              "  'hardly': 0,\n",
              "  'yearit': 1,\n",
              "  'emma': 0,\n",
              "  'special': 1,\n",
              "  'fulllength': 1,\n",
              "  'romney': 1,\n",
              "  'indicated': 1,\n",
              "  'wear': 1,\n",
              "  '1761': 0,\n",
              "  'lightly': 1,\n",
              "  'left': 0,\n",
              "  'dark': 1,\n",
              "  'round': 1,\n",
              "  'lady': 1,\n",
              "  'sleeve': 1,\n",
              "  'landscape': 1,\n",
              "  'thoughtful': 1,\n",
              "  'tell': 0,\n",
              "  '1789': 1,\n",
              "  'died': 0,\n",
              "  'fair': 1,\n",
              "  'powerful': 1,\n",
              "  'poor': 0,\n",
              "  'george': 0,\n",
              "  'fated': 0,\n",
              "  'short': 1,\n",
              "  'wa': 1,\n",
              "  'dame': 0,\n",
              "  'smith': 0,\n",
              "  'humour': 1,\n",
              "  'dainty': 1,\n",
              "  'work': 1,\n",
              "  'moved': 0,\n",
              "  'nameit': 1,\n",
              "  'dexterously': 1,\n",
              "  'life': 0,\n",
              "  'daughter': 1}]"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "\n",
        "#BOW of All doc\n",
        "Bag_of_words=[]\n",
        "for doc in All_words:\n",
        "    Bag_of_words.append(calculateBOW(Uniq_words,doc))\n",
        "Bag_of_words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "v6VSppht0KHp",
        "outputId": "0fc3d977-42dc-49d7-a30f-fd5b559a2ac3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          0  1  2\n",
              "seldom    0  0  1\n",
              "surgeon   1  0  0\n",
              "story     1  0  0\n",
              "leave     1  0  0\n",
              "motion    0  0  1\n",
              "...      .. .. ..\n",
              "taken     0  1  0\n",
              "keyword   0  1  0\n",
              "like      0  1  0\n",
              "critical  0  1  0\n",
              "survey    0  1  0\n",
              "\n",
              "[282 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0fc77548-8c1b-4dd3-9c26-a6b5364b1470\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>seldom</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>surgeon</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>story</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>leave</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>motion</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>taken</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>keyword</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>like</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>critical</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>survey</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>282 rows  3 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0fc77548-8c1b-4dd3-9c26-a6b5364b1470')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-0fc77548-8c1b-4dd3-9c26-a6b5364b1470 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-0fc77548-8c1b-4dd3-9c26-a6b5364b1470');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "#dataframe of the given Bag of words\n",
        "#for single doc replace Bag_of_words--> Bag_of_words_single\n",
        "df_bow_all = pd.DataFrame(Bag_of_words)\n",
        "df_bow_all = df_bow_all.fillna(0)\n",
        "df_bow_all = df_bow_all.T.astype(int)\n",
        "df_bow_all"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "N4Rqiib-FJm-",
        "outputId": "940fdfe9-84d6-494c-af6e-b0f1fa197b3e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     0  1  2     WORDS\n",
              "0    0  0  1    seldom\n",
              "1    1  0  0   surgeon\n",
              "2    1  0  0     story\n",
              "3    1  0  0     leave\n",
              "4    0  0  1    motion\n",
              "..  .. .. ..       ...\n",
              "277  0  1  0     taken\n",
              "278  0  1  0   keyword\n",
              "279  0  1  0      like\n",
              "280  0  1  0  critical\n",
              "281  0  1  0    survey\n",
              "\n",
              "[282 rows x 4 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7b45fc60-0a2f-4903-8646-691cb965f571\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>WORDS</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>seldom</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>surgeon</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>story</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>leave</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>motion</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>277</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>taken</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>278</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>keyword</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>279</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>like</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>280</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>critical</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>281</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>survey</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>282 rows  4 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7b45fc60-0a2f-4903-8646-691cb965f571')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-7b45fc60-0a2f-4903-8646-691cb965f571 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-7b45fc60-0a2f-4903-8646-691cb965f571');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "df_bow_all['WORDS'] = df_bow_all.index\n",
        "pikachu=df_bow_all.reset_index()\n",
        "pikachu=pikachu.drop(columns=['index'],axis=1)\n",
        "pikachu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "JSy-YOYVFkH2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "506b315d-0a5e-494b-b226-d0543a4759d0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0, 1, 0]"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "#All_words\n",
        "# checking the words\n",
        "w=pikachu.loc[pikachu['WORDS'] == 'keyword'].values.tolist()\n",
        "word=w[0][0:3]\n",
        "word"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S_naoP7iUFzo"
      },
      "source": [
        "Simple information retrieval model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "zqTf8ufrf6BP"
      },
      "outputs": [],
      "source": [
        "# Boolean Query checking\n",
        "def query_to_token(query):\n",
        "  query = word_tokenize(query)\n",
        "  \n",
        "  final=[]\n",
        "  for word in query:\n",
        "      if word.lower() != \"and\" and word.lower() != \"or\" and word.lower() != \"not\":\n",
        "         final.append(word)\n",
        "      elif word == 'and':\n",
        "        final.append('and')\n",
        "      elif word == 'not':\n",
        "        final.append('not')\n",
        "      else:\n",
        "        pass\n",
        "  return final"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "PrNkziyPqXFI"
      },
      "outputs": [],
      "source": [
        "from collections import deque\n",
        "\n",
        "\n",
        "class Stack:\n",
        "    def __init__(self):\n",
        "        self.__list = deque()\n",
        "\n",
        "    def push(self, key):\n",
        "        self.__list.append(key)\n",
        "\n",
        "    def pop(self):\n",
        "        return self.__list.pop()\n",
        "\n",
        "    def peek(self):\n",
        "        key = self.__list.pop()\n",
        "        self.__list.append(key)\n",
        "        return key\n",
        "\n",
        "    def is_empty(self):\n",
        "        return len(self.__list) == 0\n",
        "\n",
        "    def __str__(self):\n",
        "        return \"[\" + \", \".join(self.__list) + \"]\"\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.__list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "y7Js0dBCnJzv"
      },
      "outputs": [],
      "source": [
        "\n",
        "def precedence(token):\n",
        "    \"\"\" Precedence of supported operators \"\"\"\n",
        "    __precedence = {\"&\": 2, \"|\": 1}\n",
        "    try:\n",
        "        return __precedence[token]\n",
        "    except:\n",
        "        return -1\n",
        "\n",
        "\n",
        "def is_left_bracket(token):\n",
        "    \"\"\" Returns true if left bracket \"\"\"\n",
        "    return token == \"(\"\n",
        "\n",
        "\n",
        "def is_right_bracket(token):\n",
        "    \"\"\" Returns true if right bracket \"\"\"\n",
        "    return token == \")\"\n",
        "\n",
        "\n",
        "def is_operator(token):\n",
        "    \"\"\" Returns true if operator \"\"\"\n",
        "    return token == \"&\" or token == \"|\"\n",
        "\n",
        "\n",
        "def infix_to_postfix(tokens):\n",
        "  stack = Stack()\n",
        "  postfix = list()\n",
        "\n",
        "  for token in tokens:\n",
        "\n",
        "      if is_left_bracket(token):\n",
        "          # Left bracket \"(\"\n",
        "          stack.push(token)\n",
        "\n",
        "      elif is_right_bracket(token):\n",
        "          # Right bracket \")\"\n",
        "          while (not stack.is_empty()) and stack.peek() != \"(\":\n",
        "              key = stack.pop()\n",
        "              postfix.append(key)\n",
        "          if not stack.is_empty() and stack.peek() != \"(\":\n",
        "              raise ValueError(\"Query isn't well formatted\")\n",
        "          else:\n",
        "              stack.pop()\n",
        "\n",
        "      elif is_operator(token):\n",
        "          # Operator\n",
        "          while not stack.is_empty() and (\n",
        "              precedence(token) <= precedence(stack.peek())\n",
        "          ):\n",
        "              postfix.append(stack.pop())\n",
        "          stack.push(token)\n",
        "\n",
        "      else:\n",
        "          # Operand\n",
        "          postfix.append(token)\n",
        "\n",
        "  # Pop all the operator from the stack\n",
        "  while not stack.is_empty():\n",
        "      postfix.append(stack.pop())\n",
        "\n",
        "  return postfix\n",
        "def __perform_operation(left, right, op):\n",
        "      if op == \"&\":\n",
        "          return left and right\n",
        "\n",
        "      elif op == \"|\":\n",
        "          return left or right\n",
        "\n",
        "      else:\n",
        "          return 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "gGgz6JUI-Vmo"
      },
      "outputs": [],
      "source": [
        "# Function to find negation\n",
        "def Negate(word):\n",
        "  t=[]\n",
        "  ken=(pikachu.loc[pikachu[\"WORDS\"] == word.lower()].values.tolist())[0][0:3]\n",
        "  for i in ken:\n",
        "    t.append(int(not i))\n",
        "\n",
        "  return t"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "6JK9vc_v549c"
      },
      "outputs": [],
      "source": [
        "def evaluate_query(query_tokens):\n",
        "  operands = Stack()\n",
        "\n",
        "  for token in query_tokens:\n",
        "\n",
        "      # Token is an operator,\n",
        "      # Pop two elements from stack and apply it.\n",
        "      if is_operator(token):\n",
        "          # Pop right operand\n",
        "          right_operand = operands.pop()\n",
        "\n",
        "          # Pop left operand\n",
        "          left_operand = operands.pop()\n",
        "\n",
        "          # Perform operation\n",
        "          result = __perform_operation(left_operand, right_operand, token)\n",
        "\n",
        "          # Push result back into the stack\n",
        "          operands.push(result)\n",
        "\n",
        "      # Token is an operand, push it to the stack\n",
        "      \n",
        "      # Make the nagation of the word\n",
        "      if token.isalpha():\n",
        "        if token[0] == \"~\":\n",
        "          token=token[1:]\n",
        "          token_to_=Negate(token)\n",
        "          #token_to_=((pikachu.loc[pikachu[\"WORDS\"] == token.lower()].values.tolist())[0][0:3]) \n",
        "          # Push it's bit vector into operand stack\n",
        "          operands.push(token_to_)\n",
        "            \n",
        "        else:\n",
        "          # Lowercasing and stemming query term\n",
        "          token_to_ =(pikachu.loc[pikachu[\"WORDS\"] == token.lower()].values.tolist())[0][0:3]\n",
        "          # Push it's bit vector into operand stack\n",
        "          operands.push(token_to_) \n",
        "\n",
        "  if len(operands) != 1:\n",
        "      print(\"Malformed query or postfix expression\")\n",
        "      return list()\n",
        "\n",
        "  # Find out documents corresponding to set bits in the vector\n",
        "  #matching_docs = [self.documents[i + 1] for i in np.where(operands.peek())[0]]\n",
        "\n",
        "  return operands.pop()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "LeOCcjZUBh0r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8b699ba2-89fa-4b92-d7cd-eccbc94ff8b5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter your query:(artist & colour)\n",
            "('(', 'artist', '&', 'colour', ')')\n",
            "['artist', 'colour', '&']\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0, 1, 0]"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ],
      "source": [
        "query = input('Enter your query:')\n",
        "EX_list=query_to_token(query)\n",
        "# trial \n",
        "#((painted & broad ) &  ~powerful)\n",
        "#((painted & married) & (sitting & powerful))\n",
        "#(artist & colour)\n",
        "print(tuple(EX_list))\n",
        "new=infix_to_postfix(tuple(EX_list))\n",
        "print(new)\n",
        "r=evaluate_query(new)\n",
        "print(r)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# there is still some error i couldn't get the negation part so this will be updated again"
      ],
      "metadata": {
        "id": "9LqMVDi7OAgn"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "q3oUlaSJVaiO"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}